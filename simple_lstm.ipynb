{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print('Loading Data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(max_features))\n",
    "# print(max_feautres[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Padding sequences (samples x time)')\n",
    "# X_train(number of sequences) = 25000\n",
    "# maxlen(Maximum length of each sequence) = 80\n",
    "# sequence.pad_sequences() returns a 2d numpy array of shape (nb_samples, nb_timesteps)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "# The embedding layer can only be used as the first layer in a model\n",
    "# The embedding layer turns indices into dense vectors of a fixed size\n",
    "# In this case, the embedding layer turns each character in the 20000 long max_features array into 128 dimensional vectors\n",
    "model.add(Embedding(max_features, 128, dropout=0.2))\n",
    "# LSTM output dimension = 128\n",
    "# Dropout with respect to the input of the layer\n",
    "# Dropout with respect to the output of the layer.\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))\n",
    "# Dense refers tot the fully connected layer and it has an output of 1 dimension.\n",
    "model.add(Dense(1))\n",
    "# A sigmoid activation is acted upon the Dense layer output above.\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_2 (Embedding)          (None, None, 128)     2560000     embedding_input_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 128)           131584      embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1)             129         lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 1)             0           dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2691713\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile receives 3 arguments loss, optimizer and metrics\n",
    "# Loss function is the function that the model tries to minimize.\n",
    "# The optimizer is generally a string optimizer.\n",
    "# Metric is a way to see the effectiveness of a model.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.2876 - acc: 0.8839 - val_loss: 0.3821 - val_acc: 0.8421\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.2407 - acc: 0.9018 - val_loss: 0.4105 - val_acc: 0.8388\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.2003 - acc: 0.9216 - val_loss: 0.4193 - val_acc: 0.8322\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.1655 - acc: 0.9367 - val_loss: 0.4753 - val_acc: 0.8319\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.1435 - acc: 0.9452 - val_loss: 0.4999 - val_acc: 0.8228\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.1209 - acc: 0.9536 - val_loss: 0.5110 - val_acc: 0.8233\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.1021 - acc: 0.9627 - val_loss: 0.5929 - val_acc: 0.8220\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.0958 - acc: 0.9649 - val_loss: 0.6079 - val_acc: 0.8264\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.0861 - acc: 0.9678 - val_loss: 0.6039 - val_acc: 0.8218\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 116s - loss: 0.0790 - acc: 0.9708 - val_loss: 0.6609 - val_acc: 0.8081\n",
      "25000/25000 [==============================] - 35s    \n",
      "Test Score: 0.660858399563\n",
      "Test Accuracy: 0.80808\n"
     ]
    }
   ],
   "source": [
    "print('Training Model...')\n",
    "# \"fit\" trains the model for a certain number of epochs.\n",
    "# parameters X_train = input data\n",
    "# y_train = output data\n",
    "# batch_size = number of samples per gradient update\n",
    "# nb_epoch = number of epochs to train the model\n",
    "# Validation data is the data on which the model is validated, in this case the test data\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate calculates the loss on some input data batch by batch.\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size = batch_size)\n",
    "\n",
    "print('Test Score:', score)\n",
    "print('Test Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
